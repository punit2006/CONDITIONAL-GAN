# -*- coding: utf-8 -*-
"""2. CGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1krLKX8JubAF2zlrOnY-JnjXX6y5x0wms
"""

!pip install torch torchvision matplotlib numpy

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

# Parameters
img_size = 28
num_classes = 2  # "circle" and "square"
latent_dim = 100
batch_size = 32
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Helper: Generate simple images
def generate_shape(label, size=img_size):
    img = np.zeros((size, size), dtype=np.float32)
    if label == 0:  # Circle
        rr, cc = np.ogrid[:size, :size]
        mask = (rr - size//2)**2 + (cc - size//2)**2 < (size//3)**2
        img[mask] = 1.0
    else:  # Square
        img[size//4:3*size//4, size//4:3*size//4] = 1.0
    return img

# Dataset
def get_batch(batch_size):
    labels = np.random.randint(0, num_classes, batch_size)
    imgs = np.stack([generate_shape(l) for l in labels])
    return torch.tensor(imgs).unsqueeze(1), torch.tensor(labels)

# One-hot encoding
def one_hot(labels, num_classes):
    return torch.eye(num_classes)[labels].to(device)

# Generator
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.label_emb = nn.Linear(num_classes, 16)
        self.model = nn.Sequential(
            nn.Linear(latent_dim + 16, 128),
            nn.ReLU(),
            nn.Linear(128, img_size*img_size),
            nn.Sigmoid()
        )

    def forward(self, noise, labels):
        label_input = self.label_emb(labels)
        x = torch.cat([noise, label_input], 1)
        img = self.model(x)
        return img.view(-1, 1, img_size, img_size)

# Discriminator
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.label_emb = nn.Linear(num_classes, 16)
        self.model = nn.Sequential(
            nn.Linear(img_size*img_size + 16, 128),
            nn.LeakyReLU(0.2),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, img, labels):
        label_input = self.label_emb(labels)
        x = torch.cat([img.view(img.size(0), -1), label_input], 1)
        validity = self.model(x)
        return validity

# Initialize models
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Optimizers
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)
adversarial_loss = nn.BCELoss()

# Training loop (short version)
for epoch in range(1000):
    # Train Discriminator
    real_imgs, labels = get_batch(batch_size)
    real_imgs, labels = real_imgs.to(device), labels.to(device)
    valid = torch.ones(batch_size, 1, device=device)
    fake = torch.zeros(batch_size, 1, device=device)

    real_labels = one_hot(labels, num_classes)
    optimizer_D.zero_grad()
    real_loss = adversarial_loss(discriminator(real_imgs, real_labels), valid)

    z = torch.randn(batch_size, latent_dim, device=device)
    gen_labels = torch.randint(0, num_classes, (batch_size,), device=device)
    gen_labels_oh = one_hot(gen_labels, num_classes)
    gen_imgs = generator(z, gen_labels_oh)
    fake_loss = adversarial_loss(discriminator(gen_imgs.detach(), gen_labels_oh), fake)

    d_loss = (real_loss + fake_loss) / 2
    d_loss.backward()
    optimizer_D.step()

    # Train Generator
    optimizer_G.zero_grad()
    gen_loss = adversarial_loss(discriminator(gen_imgs, gen_labels_oh), valid)
    gen_loss.backward()
    optimizer_G.step()

    if epoch % 100 == 0:
        print(f"Epoch {epoch} D loss: {d_loss.item():.4f} G loss: {gen_loss.item():.4f}")

# Generate samples
generator.eval()
z = torch.randn(8, latent_dim, device=device)
labels = torch.tensor([0, 1, 0, 1, 0, 1, 0, 1], device=device)
labels_oh = one_hot(labels, num_classes)
samples = generator(z, labels_oh).cpu().detach().numpy()

# Plot
fig, axs = plt.subplots(1, 8, figsize=(16, 2))
for i, ax in enumerate(axs):
    ax.imshow(samples[i, 0], cmap='gray')
    ax.set_title("Circle" if labels[i]==0 else "Square")
    ax.axis('off')
plt.show()

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

# Parameters
img_size = 28
num_classes = 2  # "circle" and "square"
latent_dim = 100
batch_size = 64
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Helper: Generate simple images
def generate_shape(label, size=img_size):
    img = np.zeros((size, size), dtype=np.float32)
    if label == 0:  # Circle
        rr, cc = np.ogrid[:size, :size]
        mask = (rr - size//2)**2 + (cc - size//2)**2 < (size//3)**2
        img[mask] = 1.0
    else:  # Square
        img[size//4:3*size//4, size//4:3*size//4] = 1.0
    return img

# Dataset
def get_batch(batch_size):
    labels = np.random.randint(0, num_classes, batch_size)
    imgs = np.stack([generate_shape(l) for l in labels])
    return torch.tensor(imgs).unsqueeze(1), torch.tensor(labels)

# One-hot encoding
def one_hot(labels, num_classes):
    return torch.eye(num_classes)[labels].to(device)

# Generator
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.label_emb = nn.Embedding(num_classes, num_classes)

        self.model = nn.Sequential(
            nn.Linear(latent_dim + num_classes, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.LeakyReLU(0.2),
            nn.Linear(1024, img_size*img_size),
            nn.Sigmoid()
        )

    def forward(self, noise, labels):
        label_input = self.label_emb(labels)
        x = torch.cat([noise, label_input], 1)
        img = self.model(x)
        return img.view(-1, 1, img_size, img_size)

# Discriminator
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.label_emb = nn.Embedding(num_classes, num_classes)

        self.model = nn.Sequential(
            nn.Linear(img_size*img_size + num_classes, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, img, labels):
        label_input = self.label_emb(labels)
        x = torch.cat([img.view(img.size(0), -1), label_input], 1)
        validity = self.model(x)
        return validity

# Initialize models
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Optimizers
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

adversarial_loss = nn.BCELoss()

# Training loop
for epoch in range(10000):
    # Train Discriminator
    real_imgs, labels = get_batch(batch_size)
    real_imgs, labels = real_imgs.to(device), labels.to(device)
    valid = torch.ones(batch_size, 1, device=device)
    fake = torch.zeros(batch_size, 1, device=device)

    optimizer_D.zero_grad()
    real_loss = adversarial_loss(discriminator(real_imgs, labels), valid)

    z = torch.randn(batch_size, latent_dim, device=device)
    gen_labels = torch.randint(0, num_classes, (batch_size,), device=device)
    gen_imgs = generator(z, gen_labels)
    fake_loss = adversarial_loss(discriminator(gen_imgs.detach(), gen_labels), fake)

    d_loss = (real_loss + fake_loss) / 2
    d_loss.backward()
    optimizer_D.step()

    # Train Generator
    optimizer_G.zero_grad()
    gen_loss = adversarial_loss(discriminator(gen_imgs, gen_labels), valid)
    gen_loss.backward()
    optimizer_G.step()

    if epoch % 1000 == 0:
        print(f"Epoch {epoch} D loss: {d_loss.item():.4f} G loss: {gen_loss.item():.4f}")

# Generate samples
generator.eval()
z = torch.randn(8, latent_dim, device=device)
labels = torch.tensor([0, 1, 0, 1, 0, 1, 0, 1], device=device)
samples = generator(z, labels).cpu().detach().numpy()

# Plot
fig, axs = plt.subplots(1, 8, figsize=(16, 2))
for i, ax in enumerate(axs):
    ax.imshow(samples[i, 0], cmap='gray')
    ax.set_title("Circle" if labels[i]==0 else "Square")
    ax.axis('off')
plt.show()

